# -*- coding: utf-8 -*-
"""End-End Hospital (Structured) Data Model Classificication - Milestone Project_1

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UefNyQZBCKOryqsdZCIs1ImqIaQZkv8g
"""

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd

"""# **Predicitng heart disease usiong ML**

THis notebook looks into using various Python-based ML and DS libraries in an attempt tp build a ML model capable of prediciting if or not someone has heart disease based on their medical attributes

**Approach:**

1. Problem Definition
2. Data: https://archive.ics.uci.edu/dataset/45/heart+disease
3. Evaluation
4. Features
5. Modelling
6. Experimentation

## 1. Problem Definition

In a statement,
> given climincal parameters, can we predict whether they have heart disease or not

## 2. Data

Additional Variable Information

Only 14 attributes used:
      1. #3  (age)       
      2. #4  (sex)       
      3. #9  (cp)        
      4. #10 (trestbps)  
      5. #12 (chol)      
      6. #16 (fbs)       
      7. #19 (restecg)   
      8. #32 (thalach)   
      9. #38 (exang)     
      10. #40 (oldpeak)   
      11. #41 (slope)     
      12. #44 (ca)        
      13. #51 (thal)      
      14. #58 (num)       (the predicted attribute)

## 3. Evaluation

> *this is a proof of concept phase and would need accuracy above 95%.
> a*so if the model can reach 95% accuracy at prediciting whether or not a patience has heart disease during the proof of concept, we'll pursue the project

## 4. Features

This is where you'll get different information about each of the features in your data/

** Create data dictionary**

* id (Unique id for each patient)
* age (Age of the patient in years)
* origin (place of study)
* sex (Male/Female)
* cp chest pain type ([0: typical angina, 1: atypical angina, 2: non-anginal, 3: asymptomatic])
* trestbps resting blood pressure (resting blood pressure (in mm Hg on  admission to the hospital)
** anything above 130-140 is typically cause for concern
* chol (serum cholesterol in mg/dl)
  ** serum = LDL + HDL + .2 * triglycerides
  ** above 200 is cause for concern
* fbs (if fasting blood sugar > 120 mg/dl)
  ** 1 = true; 0 = false
  ** '>126' mg/dL signals diabetes
* restecg (resting electrocardiographic results)
-- Values: [0: normal, 1: stt abnormality, 2: lv hypertrophy]
* thalach: maximum heart rate achieved
* exang: exercise-induced angina (1 = True/ 0 = False)
* oldpeak: ST depression induced by exercise relative to rest
* slope: the slope of the peak exercise ST segment
  ** 0: Upsloping: better heart rate with exercise (uncommon)
  ** 1: Flatsloping: minimal change (typical healthy heart)
  ** 2: Downslopings: signs unhealthy heart
* ca: number of major vessels (0-3) colored by fluoroscopy
  ** color vessel means the doctoc can see the blood passing through
  ** the more blood movement the better (no clots)
* thal - thalium stress results: [1,3:normal; 6:fixed defect - used to be defect but ok now; 7: reversible defect - no propper blood movement when exercising]
* num: the predicted attribute (0 or 1)

## **Preparing the Tools**

We're going to use pandas, Matplotlib, and NumPy for data analysis and manipulation
"""

!pip uninstall scikit-learn -y
!pip install scikit-learn

# Commented out IPython magic to ensure Python compatibility.
# Import all the tools

# Regular EDA (Exploratory data analysis) and plotting libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# This line ensures that plots appear inside the notebook
# %matplotlib inline

# Models from SK-Learn
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier

# Model Evaluation
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.model_selection import RandomizedSearchCV, GridSearchCV
from sklearn.metrics import confusion_matrix, classification_report
from sklearn.metrics import precision_score, recall_score, f1_score
from sklearn.metrics import RocCurveDisplay, PrecisionRecallDisplay, ConfusionMatrixDisplay

"""## **Load Data**"""

from google.colab import files
uploaded = files.upload()

file_name = next(iter(uploaded))

# Read the CSV file into a DataFrame
df = pd.read_csv(file_name)

# Display the first few rows of the DataFrame
df

df.shape # (rows, columns)

"""## **Data Exploration (exploratory data analysis or EDA)**
### the goal is to find more about your data and become a subject matter expert on the dataset you are working

1. What quesdtions are you trying to solve?
2. what kind of data do we have and how do we treat different types?
3. whats missing from data ands how do you deal with it?
4. ANy outliers and why should we care about them?
5. How can you add, change, or remove featyres to get more out of the data
"""

df.head()

df.target.value_counts() # find how many of each class we have

"""based on 0 & 1 numbers, seems like a balanced classification problm"""

df.target.value_counts().plot(kind='bar', color=['salmon', 'lightblue']);

df.info()

df.isna().sum() # to find any missing values

df.describe()

"""### Heart Disease Frequency according to Sex
* we are just getting some exploratory feel of the data
"""

df.sex.value_counts() # 0 is women and 1 is men

# Cimpare target column with sex column
pd.crosstab(df.target, df.sex)

"""so we can say that based on our current existing data:
* 75% of women might have chance of heart disease vs,
* 45% in men

All together there is 62.5% chance there is heart disease

(so all this is just developing our intution for the data)
"""

#visualize

pd.crosstab(df.target, df.sex).plot(kind='bar',
                                    figsize=(10,6),
                                    color=['salmon', 'lightblue']);

plt.title('Heart Disease Frequency for Sex')
plt.xlabel('0 = No Disease, 1 = Disease')
plt.ylabel('Amount')
plt.legend(['Female', 'Male']);
plt.xticks(rotation=0);

# lets combine couple of independent variables and compare to the target variables

df.thalach.value_counts()

"""based on the dictionary, we know that thalach is max heart rate achieved.

and based on the number of values (91 disticnt values) we know that a scatter plot will be better compared to a bar graph

### Age vs Max Heart Rate for Heart Disease
"""

# create another figure
plt.figure(figsize=(10,6))

# Scatter with postive examples
plt.scatter(df.age[df.target==1], #so we are only taking those age values where the target is 1
            df.thalach[df.target==1], # same, its for the subset where target is 1
            c='salmon')

#scatter with neegative examples
plt.scatter(df.age[df.target==0],
            df.thalach[df.target==0],
            c='lightblue')

# Add some helpful info
plt.title('Heart Disease in function of Age and Max Heart Rate')
plt.xlabel('Age')
plt.ylabel('Max Heart Rate')
plt.legend(['target 1', 'target 0'])
plt.show()

"""so just by the visuals, we can tell that the heart rate is decreasing as you are aging up but its very hard to find a pattern how these two are relating to the heart disease.
thats why a **ML Model** will be needed
"""

# check distribution of the age column
df.age.plot(kind='hist', bins=100);

"""so these distributions for say each column tells us if there are any **outliers** in our samples.
these outliers should be cleaned

**Lets compare other data columns**

* chest pain vs target

* cp chest pain type ([0: typical angina, 1: atypical angina, 2: non-anginal, 3: asymptomatic])
"""

pd.crosstab(df.cp, df.target).plot(kind='bar',
                                   figsize=(10,6),
                                   color=['salmon', 'lightblue'])

# Add some labels
plt.title('Heart Disease Frequency per Chest Pain Type')
plt.xlabel('Chest Pain Type')
plt.ylabel('Amount')
plt.legend(['No Disease', 'Disease'])
plt.xticks(rotation=0);

"""so we can see that as cp is increaseing to higher values, the heart disease is also increasing.
But someone with medical profession can tell that when cp value is 2 i.e. non-anginal, how its effecting the heart disease.

**Lets use a corelation matrix to see relation b/w independent vs dependent variables**
"""

# Male a corelation matrix
df.corr()

# Lets make it more visual
corr_matrix = df.corr()
fig, ax = plt.subplots(figsize=(15,10))
ax = sns.heatmap(corr_matrix,
                 annot=True,
                 linewidths=0.5,
                 fmt='.2f',
                 cmap='YlGnBu');

"""* A higher postive value means a higher potenial positive corelation
* A higher negative value meas a higher negative corelation

  * so as cp goes up, the target value also increase
  * as exang (exercise induced heart pain) goes down, so should the target value
    * so it means, just based on corelation that if someone gets chest pain during exercise (exang = 1), their chance of having heart disease goes down (target = 0)
* if correlation is 0 i.e in case of fbs, we can say there is no correlation

## **5. Model Driven EDA (Modelling)**

i.e instead of doing it manually, we want to do a model machine learning based exploratory data analysis
"""

# Split data into X and Y
X = df.drop('target', axis=1)
y = df['target']

X

y

# Training and Test split
np.random.seed(42)

# Split into train and test set
X_train, X_test, y_train, y_test = train_test_split(X,
                                                    y,
                                                    test_size=0.2)

len(X_train), len(X_test), len(y_train), len(y_test)

"""Now that the data is split, time to build a model

Model will be trained to find patterns on the training set and it will be used on the test set to apply those patterns

https://scikit-learn.org/stable/machine_learning_map.htmls

We are going to try 3 diff ML models

1. Logistic Regression
2. K-Nearest Neighbours Classifier
3. Random Forest Classifer (ensemble)
"""

# Put models in a dictionary
models = {'Logistic Regression': LogisticRegression(),
          'KNN': KNeighborsClassifier(),
          'Random Forest': RandomForestClassifier()}

# Create a function to fit and score models
def fit_and_score(models, X_train, X_test, y_train, y_test):
  """
  Fits and evaluates given machine learning models.
  models : a dict of diferent Scikit-Learn machine learning models
  X_train : training data (no labels)
  X_test : testing data (no labels)
  y_train : training labels
  y_test : test labels
  """
  # Set random seed
  np.random.seed(42)
  # Make a dictionary to keep model scores
  model_scores = {}
  # Loop through models
  for name, model in models.items():
    # Fit the model to the data
    model.fit(X_train, y_train)
    # Evaluate the model and append its score to model_scores
    model.score(X_test, y_test)
    model_scores[name] = model.score(X_test, y_test)
  return model_scores

model_scores = fit_and_score(models=models,
                             X_train=X_train,
                             X_test=X_test,
                             y_train=y_train,
                             y_test=y_test)
model_scores

"""* so we see that Logistic Regression is getting the best score (max score = 1) out of all three models

## Model Comparision
"""

model_compare = pd.DataFrame(model_scores, index=['accuracy'])
model_compare.T.plot.bar(); #T is for transpose

"""so we know Logistic Regression is good but how can we improve it? i.e. how can the baseline model be improve.

We will be working on following:

1. Hyperparameter tuning
2. Feature importance
3. Confusion-matrix
4. cross validation
5. precision
6. recall
7. F1 score
8. classification report
9. ROC curver
10. Area under the curve (AUC)

* 1&2 aapply to any ML model
* rest apply to classification problem only in specific

### **Hyperparameter tuning**
"""

# Lets tune KNN
train_scores = []
test_scores = []

# Create a list of different values for n_neighbours

neighbors = range(1,21)

# Setup KNN instance
knn = KNeighborsClassifier()

# Loop through different n_neighbors
for i in neighbors:
  knn.set_params(n_neighbors=i)

  # Fit the algorithm
  knn.fit(X_train, y_train)

  # Update the training
  train_scores.append(knn.score(X_train, y_train))
  # Update the test score list
  test_scores.append(knn.score(X_test, y_test))

test_scores

plt.plot(neighbors, train_scores, label='Train score')
plt.plot(neighbors, test_scores, label='Test score')
plt.xticks(np.arange(1,21,1))
plt.xlabel('Number of neighbors')
plt.ylabel('Model score')
plt.legend()

print(f'Maximum KNN score on the test data: {max(test_scores)*100:.2f}%')

"""* so the n-neighbours of value = 11 is giving the best results vs the default which was 5

* but still the best result is only giving 75% which is way less than other models so we can safely say that no need to go ahead with this model

## Hyperparameter tuning with RandomizedSearch CV
https://scikit-learn.org/0.16/modules/generated/sklearn.grid_search.RandomizedSearchCV.html#:~:text=Randomized%20search%20on%20hyper%20parameters,is%20optimized%20by%20cross%2Dvalidation.

We are going to tune:
* LogisticRegression()
* RandomForestClassifier()
....using RandomizedSearchCV

CV = cross validation i.e. instead of doing a one train test split, it creates a k fold cross validation (5 is default in SKlearn)

So 5 diff version of train and test data will be created and various versions of hyperparameters will be tested on each of these splits
"""

# Create a hyperparameter grid for logistc regression

log_reg_grid = {'C': np.logspace(-4, 4, 20), #logspace returns numbers evenly on a log scale
                'solver': ['liblinear']}

# so anove we are basically just testing the C which is the most important parameter for logistic regression

## Create a hyperparameter grid for RandomForestClassifier
rf_grid = {'n_estimators': np.arange(10, 1000, 50),
           "max_depth": [None, 3, 5, 10],
           "min_samples_split": np.arange(2, 20, 2),
           "min_samples_leaf": np.arange(1, 20, 2),}
          #"max_features": [0.5, 1, "sqrt", "auto"],
           #"max_samples": [10000]}

"""Now we have got hyperparameters grids setup for each model, lets tune these using RandomizedSearchCV"""

# Tune LogisticRegression

np.random.seed(42)

# Setup random hyperparameter search for Logistic Regression
rs_log_reg = RandomizedSearchCV(LogisticRegression(),
                                param_distributions=log_reg_grid,
                                cv=5, # 5 fold cross validation
                                n_iter=20,
                                verbose=True)

# Fit random hyperparameter search model for Logistic Regression
rs_log_reg.fit(X_train, y_train)

rs_log_reg.best_params_

# Lets evaluate
rs_log_reg.score(X_test, y_test)

"""* our previous results for logisticregression was .8852459016393442, so hypertuning did not improve much here"""

# tuning randomforest now
np.random.seed(42)

# Setup random hyperparameter search for Random Forest Classifier
rs_rf = RandomizedSearchCV(RandomForestClassifier(),
                                param_distributions=rf_grid,
                                cv=5, # 5 fold cross validation
                                n_iter=20,
                                verbose=True)
rs_rf.fit(X_train, y_train)

rs_rf.best_params_

rs_rf.score(X_test, y_test)

"""**so we can see that our socre has improve from 0.83 to 0.86 using hyperparameter tuning**"""

model_scores

"""## **GridSearchCV()** - Hyperparameter Tuning
now after doing by hand and randomized search CV, lets improve the hyperparameters using GridSearchCV

https://scikit-learn.org/dev/modules/generated/sklearn.model_selection.GridSearchCV.html

**Note:** we will do this only for LogisticRegression since this is the model which has been giving the best results so far
"""

# Different hyperparameters for our LogisticRegression model

log_reg_grid = {'C': np.logspace(-4, 4, 30),
                'solver': ['liblinear']}

# Setup grid hyperparameter search for Logistic Regresison
gs_log_reg = GridSearchCV(LogisticRegression(),
                          param_grid=log_reg_grid, # this is the line which is different b/w gridsearch and randomizedserach and also n_iter b/c gridsearch looks for all possible ns. that is why its extensive
                          cv=5,
                          verbose=True)

# Fit grid hyperparamets serach moidels
gs_log_reg.fit(X_train, y_train)

gs_log_reg.best_params_

gs_log_reg.score(X_test, y_test) # evaluting the grid search LogisticRegression model

"""so it means the score is still good and close to the basline model.

**hypertuning more params as well**
"""

import numpy as np
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import GridSearchCV

# Different hyperparameters for our LogisticRegression model
log_reg_grid = {
    'C': np.logspace(-4, 4, 30),
    'solver': ['liblinear', 'saga'],  # Added 'saga' for larger datasets
    'penalty': ['l1', 'l2'],            # Regularization types
    'max_iter': [100, 200, 300],        # Maximum iterations
    'class_weight': [None, 'balanced']   # Class weight options
}

# Setup grid hyperparameter search for Logistic Regression
gs_log_reg = GridSearchCV(LogisticRegression(),
                           param_grid=log_reg_grid,
                           cv=5,
                           verbose=True)

# Fit grid hyperparameter search models
gs_log_reg.fit(X_train, y_train)

gs_log_reg.best_params_

gs_log_reg.score(X_test, y_test)

"""**still the same**

## Evaluting ML calssifier, beyond accuracy

* ROC curve and AUC score
* COnfusion matrix
* Classfication report
* Recall
* F1-score

... and it would be great if cross validation was used where possible.

**Note:** to maker comparisions and evaluate our trained model, first we need to make predictions
"""

# Make predictions with tune model
y_preds = gs_log_reg.predict(X_test)

y_preds

y_test

"""* so manually we can see that there is some error b/w the y_preds and y_test but we will write a code to do such things and evaluations for us

**ROC Curve:** plots true positive rate against false positve rate at various thresholds

Note: roc curve exists in sklearn metrics
"""

from sklearn.metrics import RocCurveDisplay

# Plot ROC curve for the best model from GridSearchCV
RocCurveDisplay.from_estimator(gs_log_reg, X_test, y_test)

# Confusion Matrix

# Import Seaborn
import seaborn as sns
sns.set(font_scale=1.5) # Increase font size

def plot_conf_mat(y_test, y_preds):
   """
   Plots a confusion matrix using Seaborn's heatmap().
   """
   fig, ax = plt.subplots(figsize=(3, 3))
   ax = sns.heatmap(confusion_matrix(y_test, y_preds),
                    annot=True, # Annotate the boxes
                    cbar=False)
   plt.xlabel("Predicted label") # predictions go on the x-axis
   plt.ylabel("True label") # true labels go on the y-axis

plot_conf_mat(y_test, y_preds)

"""so the matrix is telling us that model predicted:



*  3 false negative
*  4 false positive

**Next:**

* accuracy
* classification report
* cross validated precision
* recall
* f1-score
"""

print(classification_report(y_test, y_preds))

"""* so this report is only done on one test data i.e one split. Not on cross valdiation where 5 differnet splits are done to see which split does better

### Evalute using Cross Validation

*parameter: scoring
"""

# Chec best hyperparametere
gs_log_reg.best_params_

# Creata new classifier with best params
clf = LogisticRegression(C=0.20433597178569418,
                         class_weight=None,
                         max_iter=100,
                         penalty='l2',
                         solver='liblinear')

# Cross validated accuracy

cv_ac = cross_val_score(clf,
                        X, # we can pass all the x and y data becasue we are passing all the data
                        y,
                        cv=5,
                        scoring='accuracy')
cv_ac

cv_ac.mean()

# Cross validated Precision
cv_pr = cross_val_score(clf,
                        X, # we can pass all the x and y data becasue we are passing all the data
                        y,
                        cv=5,
                        scoring='precision')
cv_pr = np.mean(cv_pr)
cv_pr

# Cross validated recall
cv_re = cross_val_score(clf,
                        X, # we can pass all the x and y data becasue we are passing all the data
                        y,
                        cv=5,
                        scoring='recall')
cv_re = np.mean(cv_re)
cv_re

# Cross validated f1-score
cv_f1 = cross_val_score(clf,
                        X, # we can pass all the x and y data becasue we are passing all the data
                        y,
                        cv=5,
                        scoring='f1')
cv_f1 = np.mean(cv_f1)
cv_f1

# Let's visualize cross-validation metrics
cv_metrics = pd.DataFrame({'Accuracy': cv_ac,
                           'Precision': cv_pr,
                           'Recall': cv_re,
                           'F1': cv_f1},
                          index=[0])  # Index should match the length of your data

# cv_metrics.T.plot.bar(title='Cross-Validation Metrics', legend=False);

# Check if metrics are arrays/lists and take the mean if necessary
cv_ac = np.mean(cv_ac) if isinstance(cv_ac, (list, np.ndarray)) else cv_ac
cv_pr = np.mean(cv_pr) if isinstance(cv_pr, (list, np.ndarray)) else cv_pr
cv_re = np.mean(cv_re) if isinstance(cv_re, (list, np.ndarray)) else cv_re
cv_f1 = np.mean(cv_f1) if isinstance(cv_f1, (list, np.ndarray)) else cv_f1

# Let's visualize cross-validation metrics
cv_metrics = pd.DataFrame({'Metric': ['Accuracy', 'Precision', 'Recall', 'F1'],
                           'Score': [cv_ac, cv_pr, cv_re, cv_f1]})

# Plot the metrics
cv_metrics.plot.bar(x='Metric', y='Score', title='Cross-validated metrics', legend=False)

"""### **Feature Importance**

Feature importance is another as asking, "Which features contributed most to the outcomes of hte model and how did they contribute?"

Find fearture importnace is diff from each machine learning model

https://stackoverflow.com/questions/34052115/how-to-find-the-importance-of-the-features-for-a-logistic-regression-model

Onw way to find featyure importnbat is: "(MODEL NAME) feature importance"
"""

# Fit an instace of LogisticRegression
gs_long_reg = LogisticRegression()
gs_log_reg

clf = LogisticRegression(C=0.20433597178569418,
                         class_weight=None,
                         max_iter=100,
                         penalty='l2',
                         solver='liblinear')
clf.fit(X_train, y_train)

df.head()

# Check coef_
clf.coef_

"""* so its telling us that how each of the parameter in the x_train dataset contributed to the target variable"""

# mathc coef's of features to columns
feature_dict = dict(zip(df.columns, clf.coef_[0]))
feature_dict

# vISUALIZE feature importance
feature_df = pd.DataFrame(feature_dict, index=[0])
feature_df.T.plot.bar(title='Feature Importance', legend=False)

pd.crosstab(df['sex'], df['target'])

"""so this can be see in our graph that as sex is increasing (0 to 1) target value ratio is decreasing. so its a negative corelation

# Slope

slope: the slope of the peak exercise ST segment ** 0: Upsloping: better heart rate with exercise (uncommon) ** 1: Flatsloping: minimal change (typical healthy heart) ** 2: Downslopings: signs unhealthy heart
"""

pd.crosstab(df['slope'], df['target'])

"""so slope 2 is unhealthy heart so as the heart is getting healhty, the chances of getting heart attach are getting more"""

